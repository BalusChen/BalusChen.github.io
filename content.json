{"pages":[{"title":"关于我","text":"陈建勇，网上常用昵称 balus，邮箱 balus@foxmail.com 现就职于抖音商业化服务端，个人兴趣包含但不仅限于： Linux、macOS Golang/C/C++/Lua Nginx/Redis/LevelDB/LLVM 性能优化 Q&amp;A 网站名为 laputa，有什么寓意？ 是宫崎骏《天空之城》中的一个地名 头像是？ 《魁拔》中的蛮吉 balus 是？ 是《天空之城》两位主角念的一句咒语 网站 logo 为什么是半个猕猴桃？ 喜欢它的味道和颜色，当然也很喜欢吃","link":"/about/index.html"}],"posts":[{"title":"git-一些很有用的技巧","text":"压缩提交很多时候 搜索1git log -L :LoadMaterial:ad_loder.go:","link":"/2020/09/19/git-%E4%B8%80%E4%BA%9B%E5%BE%88%E6%9C%89%E7%94%A8%E7%9A%84%E6%8A%80%E5%B7%A7/"},{"title":"git-一些知识点","text":"背景今天听了组内同学为校招新同学做的 git 分享，虽然之前也看过诸如《Pro Git》之类的书，但是还是学到了一些知识点；而且通过这次分享，也发现自己对 git 基本概念和原理的了解并不充分也不深刻，所以想借此机会查缺补漏，把学会的各个知识点以笔记的方式记录下来。 多分支操作git 和其他 VCS 区别最大的一点就是其分支功能， ~和^的区别参考SO: ~和^的区别","link":"/2020/09/21/git-%E4%B8%80%E4%BA%9B%E7%9F%A5%E8%AF%86%E7%82%B9/"},{"title":"golang-如何实现websocket协议","text":"golang 如何实现 websocket 协议最近一直在想着在 nginx 上实现 websocket 协议，但是却没有太多头绪，所以 clone 了一些 golang websocket 相关的 repo 下来学习。既是学习它对 websocket 协议包的处理，也希望对 golang 本身有更多的理解（包括对标准库的熟悉）。 一些不懂的地方golang 如何接管 HTTP 连接websocket 是通过 HTTP 发起请求，并且带上一些特殊的请求头告诉 server 需要升级协议至 websocket，server 同意升级后回复相应的状态码和几个特殊的响应头，此后所有的数据都以 websocket 协议来进行解析。 所以我们需要一种机制，在第一次以 HTTP 协议接收请求并响应之后可以接管 TCP 连接，而后的所有数据由自己来解析，而不再通过 HTTP 协议。而 golang 也的确提供了这种能力，即 hijack（劫持）。 1234// net/http/server.gotype Hijacker interface { Hijack() (net.Conn, *bufio.ReadWriter, error)} Hijack方法让调用者接管这个连接，此后 HTTP 库不再处理这个连接，而是由调用者来管理。该方法有三个返回值： net.Conn：即 TCP 连接，需要注意的是，这个连接的 read deadline 或者 write deadline，而实际上 HTTP 中设置的值在连接被接管之后就不能再影响这个连接了，所以调用者需要自己清理掉这些 deadline *bufio.ReadWriter：当连接被接管时，可能上层的HTTP连接已经读取/写入了一些数据 需要注意的是，不是所有版本的 HTTP 协议都支持 hijack，HTTP/1.x 是支持的，但是 HTTP/2 则不支持，所以在 hijack 之前需要判断该 HTTP 连接是否实现了Hijacker接口： 123456789func wsAccept(w http.ResponseWriter) { hj, ok := w.(http.Hijacker) if !ok { return } c, brw, err := hj.Hijack() ...} 前面说过，由于 HTTP 底层使用的是 TCP 协议，数据是以字节流的形式传输的，所以在读完 HTTP header 的时候，可能 body 也读取了一部分，而这部分实际上是需要以 websocket 协议来处理的。通常我们在接管连接之前，只会把握手阶段的响应头发送给 client，而不会发送 body，所以Hijack方法返回的*bufio.ReadWriter通常只有 reader 有尚未处理的数据，这些数据我们是需要复用的： 123...b, _ := brw.Reader.Peek(brw.Reader.Buffered())brw.Reader.Reset(io.MultiReader(bytes.NewReader(b), netConn)) 这里将Hijacker返回的*bufio.ReadWriter中的 reader 部分重置为io.MultiReader，这种 reader 可以从一个或者多个 read source 读取数据，正好满足目前的要求：既需要从未被处理的 reader 中读取数据，又需要从网络连接中读取数据。 client 发起 websocket 连接时，在还没有接收到 server 的 handshake response 之前也会发送数据么？感觉Hijack方法返回的*bufio.ReadWriter中的 reader 不会有未处理的数据？ 参考What is Sec-WebSocket-Key for? A Million WebSockets and Go","link":"/2020/09/19/golang-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0websocket%E5%8D%8F%E8%AE%AE/"},{"title":"hexo-why","text":"hexo 搭建博客折腾过很多次，但是其中一些疑问点一直困扰着我，而且其中也遇到了很多的坑，所以把它们记录下来。 GitHub 仓库 为什么 GitHub 仓库名一定要是 ${username}.github.io 一开始按照这篇博客提供的方法来使用 hexo 搭建博客，其中直接把仓库命名为 myblog，然后使 travis.ci 进行自动化部署 github-pages，travis 配置： 12345678910111213141516171819sudo: falselanguage: node_jsnode_js: - 12cache: npmbranches: only: - masterscript: - hexo generatedeploy: provider: pages skip-cleanup: true github-token: $GITHUB_TOKEN keep-history: true on: branch: master local-dir: public 大概的意思就是说使用 node 12 版本（本机其实已经 14.9 了），然后只在 master 分支更新时触发部署，触发时执行hexo generate这个命令，部署的类型为 github-pages；它新建一个 gh-pages 的分支，用来存储生成的数据。 然后在 _config.yml 配置文件中将 root 改为 /myblog/，这样就可以直接从 ${username}.github.io/myblog 访问（如果将仓库命名为${username}.github.io则不用修改 root，并且直接可以通过 ${username}.github.io 访问）。 但是后面在关联域名的时候就没法用了，在 DNSpod 上配置时需要配置： 其中的记录值只能是一个简单的域名，不能带有 path，他表示当访问 baluschen.github.io 时，会跳转至 laputa.world，但是我没有配置域名之前访问 baluschen.github.io 就是 404，所以后面还是把它乖乖改回标准格式了。 主题的使用主题放在 themes/ 目录下面，我一开始是直接 clone 进去的（因为想保持更新），但是在使用 travis 部署的时候却总是提示我 no layout，部署过后所有页面都是空的。而且在本地测试的时候，也会报错说有多个 git 仓库（博客本身一个，主体又又一个），所以我打算使用 git submodule 的方式来引用主题，而且其实 travis 本身也是会递归 clone 的： 12git clone --depth=50 --branch=master https://github.com/BalusChen/laputa.git BalusChen/laputagit submodule update --init --recursive 开始的 .gitmodules 文件是这样的： 123[submodule &quot;themes/icarus&quot;] path = themes/icarus url = git@github.com:ppoffice/hexo-theme-icarus.git 结果 travis 在拉取 theme repo 的时候报错： 12345678Please make sure you have the correct access rightsand the repository exists.fatal: clone of 'git@github.com:ppoffice/hexo-theme-icarus.git' into submodule path '/home/travis/build/BalusChen/laputa/themes/icarus' failedFailed to clone 'themes/icarus'. Retry scheduledCloning into '/home/travis/build/BalusChen/laputa/themes/icarus'...Warning: Permanently added the RSA host key for IP address '140.82.112.3' to the list of known hosts.Permission denied (publickey).fatal: Could not read from remote repository. 后面参考这个把 git 协议改成 https 协议就 OK 了： 123[submodule &quot;themes/icarus&quot;] path = themes/icarus url = https://github.com/ppoffice/hexo-theme-icarus.git 关联域名域名是在namesilo上买的，域名的关联比较简单，主要是域名解析的工作，我使用的是DNSPod来解析，主要工作由： 在博客中新增 CNAME 文件指定自己的域名 在 DNSPod 中新增 A 记录和 CNAME 记录 在 namesilo 替换域名服务器为 DNSPod 提供的 name server 评论系统评论系统使用gittalk搭建，首先需要在GitHub 中注册一个新的 GitHub Application，其中有两项信息很重要： Homepage URL：博客首页地址 Authorization callback URL：gittalk 需要 GitHub 登陆才可以评论，这里经过 GitHub 授权后跳转回去的地址，一般也是博客首页地址 这两个地址需要填入 _config 中，如果二者和博客地址不一样（比如 http 和 https），那么可能会出现点击 GitHub 登陆后直接就跳回主页的情况。 文章插入图片在 _config.yml 中指定 logo 等图标时，都是像/img/logo.png这样指定 img 目录下面的文件，我搜索了下这是 public 目录下面的一个子目录，但是 public 目录在 gitignore 的，即不会上传至 github。可以看看hexo generate后生成的数据： 可以看到出 source 目录下除下划线开头的文件外其它文件都被放在了根目录，所以我们只需要在 source 目录下新建一个 images 目录就可以在 Markdown 文件中直接以/images/xxx.png的方式引用了。 至于hexo generate命令生成的数据为什么是这样的，还得 RTFM 参考Icarus用户指南 - 主题配置 2020年，必须拥有自己的博客网站(上) 用Hexo + Github Pages搭建你的个人博客（2020版） Hexo博客搭建之在文章中插入图片 Hexo基础教程(二)：个人域名绑定","link":"/2020/09/12/hexo-why/"},{"title":"《程序员修炼之道》读书笔记-务实的哲学","text":"自接触编程以来，看我过的绝大部分书都是关于某项特定技术的，比如《XXX Primer》、《XXX 源码剖析》、《XXX 实战》以及 OS、网络等计算机专业课相关的。诚然，这些都是必备的，但是正式工作后，越来越感觉如何成长是一个至关重要的议题，而正好《程序员修炼之道》第二版发布了，所以打算看看这本书，而实际上书的确很棒，看第一章我就感触颇多。 一、前言 编程是一门技艺。简单地说，就是让计算机做你想让它做的事情（或者是你的用户想让它做的事情）。作为一名程序员，你既在倾听，又在献策；既是传译，又行独裁；你试图捕获难以捉摸的需求，并找到一种表达它们的方式，以便仅靠一台机器就可以从容应付。你试着把工作记录成文档，以便他人理解；你试着将工作工程化，这样别人就能在其上有所建树；更重要的是，你试图在项目时钟的滴答声中完成所有的这些工作。你每天都在创造小奇迹。 你不应该拘泥于任何特定的技术，而应该拥有足够广泛的背景和经验基础，以便在特定的情况下选择合适的解决方案。你的背景来自对计算机科学基本原理的理解，而你的经验来自广泛的实际项目。理论结合实践会让你变得强大。 调整方法去寻找适应当前的情况和环境。对所有影响项目因素的相对重要性做出判断，并通过经验找到合适的解决方案。随着工作的进展，你要不断地这样做。务实的程序员不仅把工作做完，并且做得很好。 二、务实的哲学 务实的程序员的特质是什么？是他们面临问题时，在解决方案中透出的态度，风格以及理念。他们总是越过问题的表面，试着将问题放在更宽泛的上下文中综合考虑，从大局着想。毕竟，若不去了解来龙去脉，结合实际从何谈起？又怎能做出明智的妥协和合理的决策？ 当你意识到自己在说“我不知道”时，一定要接着说“——但是我会去搞清楚”。用这样的方式来表达你的不知道是非常好的，因为接着你就可以像一个专家一样承担起责任。 不要只是因为一些东西非常危急，就去造成附带损害。破窗一扇都嫌太多。 批判性地分析你读到和听到的东西，问几个值得思考的问题： 谁从中受益 有什么背景：每件事都发生在自己的背景之下，这也是为何“能解决所有问题”的方案通常是不存在的。 什么时候可以在哪里工作起来：不要停留在一阶思维下（接下来会发生什么），要进行二阶思考（当它结束后还会发生什么？）。 为什么这是个问题：是否存在一个基础模型以及这个基础模型是怎么工作的？","link":"/2020/09/19/%E3%80%8A%E7%A8%8B%E5%BA%8F%E5%91%98%E4%BF%AE%E7%82%BC%E4%B9%8B%E9%81%93%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E5%8A%A1%E5%AE%9E%E7%9A%84%E5%93%B2%E5%AD%A6/"},{"title":"一个诡异的map并发读写问题","text":"一个诡异的 map 并发读写问题背景这两天线上的一个服务时不时地就报进程退出报警，服务主要做的事情就是打包广告相关的数据，即以 rpc 的方式调用各个下游打包数据并组装成一个大的结构返回上游；由于需要调用多个下游，所以同时起了很多 goroutine 去获取数据。 然后照常登陆实例看日志，直接less xxx.log然跳到最后一行往上翻，日志很多，大部分都是： 1 很像 goroutine 泄露的迹象，所以一开始就朝着这个方向去排查，但是找了很久没有什么思路（主要是想用 pprof 的http://ip:port/pprof/goroutine?debug=2的方式去查看，结果公司的性能分析平台不太支持debug=2的方式，而且线下难以模拟线上环境，所以一团乱麻）。 continue后面陆陆续续又报了一些问题，这次把日志从下往上一直翻到错误日志的第一行，结果发现错误日志是： 12345fatal error: concurrent map read and map writegoroutine 1 [running]:runtime.throw(0x10db16c, 0x21)... 即 map 并发读写导致的问题。问题原因确定了，但是错误日志中显示的错误发生的代码位置很诡异。 大致的代码逻辑是这样的： 1234567891011121314futures := make([]*async.Future, 0, 3)if (len(ads1) &gt; 0) { futures = append(futures, async.NewFutureWithTimeout(ctx, 300*time.Millisecond, func(context.Context) interface{} { return loadMaterial(ads1) }) ...}for _, future := range futures { res, ok := future.Get() if ok { buildMaterial(res) }} 每种广告都使用一个future去 load 数据，这块是起多个 goroutine 并发地调用下游获取数据，然后 load 完毕之后 build 成一个大结构体（build 并没有使用多个 goroutine）。问题出现在buildMaterial函数中的一条对map的读语句中，但是很奇怪的是buildMaterial中只有对该 map 的读取操作，所有的写入操作都在loadMaterial中，那么按理来说是不会发生并发读写的问题的。 后面发现原来问题出现在 future 的实现上面，这里使用的是NewFutureWithTimeout，那么要是其中的操作超出了指定的超时值（这里是 300ms），那么就直接返回 nil，但是此时 load 数据的 goroutine 并没有结束；而 为什么 panic 没有被捕获？有一点比较奇怪的是，报警报的是【进程退出】而不是【服务 panic】；一般而言，当 goroutine 因为 panic 而退出，但是 panic 被外层（或是业务代码本身，或是框架代码）的recover所捕获时，会报【服务 panic】错误，而当整个服务进程退出时则会报【进程退出】（当然进程退出后，会由 k8s 再尝试拉起）。 那么为什么 map 并发读写没有被future包中的以及rpc 框架本身的 recover 所捕获呢？ 总结参考","link":"/2020/09/19/%E4%B8%80%E4%B8%AA%E8%AF%A1%E5%BC%82%E7%9A%84map%E5%B9%B6%E5%8F%91%E8%AF%BB%E5%86%99%E9%97%AE%E9%A2%98/"},{"title":"七八月的二三事","text":"公司奉行双月 OKR 的规章制度，从七月初我正式入职到现在正好一个双月，该回过头去做些总结了。 关于工作本来是打算 7-10 入职，入职前和包子、大腿他们再吃个饭，结果 7-1 晚上收到邮件说因为我的实习期是 7-1 结束，所以如果不申请延期，lark 账号就被被注销，赶紧联系 hr 把入职时间提前到 7-1，一顿折腾，最后终于搞定了（虽然事实上是 7-2 才开始工作），但是饭局也凉了。 关于生活入手了心心念念的 iMac2020，虽然知道接下来应该就是 ARM 的天下了，但是感觉全面适配 ARM 还是需要一段时间的，所以尽管知道这可能是49年入国军，并且 iMac 还是有着可以停航母的边框，我还是买了。不过还是和往常买大件一样，东西到手就后悔了，心疼，虽然的的确确比手上公司发的 MBP 性能强劲了很多，但是还是觉得很痛心（先埋怨自己一顿，后面就可以心安理得地用了）。 前些天给 iMac 升级 big sur（毛玻璃的确非常吸引我），虽然看到了官网提示说 27-inch iMac2020 可能会有问题，但是想着以前升级从来没有失败过就还是毅然决然地升级了，结果不出意外变砖了；很郁闷，没有备份的习惯，导致刚刚配置好的环境又没了，重装也很耗时。所以马上买了一个硬盘作 Time Machine 备份用，看来还是不可心存侥幸。 一如既往，买了一大堆书，但是总感觉没有时间看；也可能是因为心态还没有调整过来，在工作中想要用大片大片的时间来学习几乎是不可能的，但是我又很抵触碎片式的学习，总感觉学了马上就忘，忘了再看又是全新，着实烦恼。 又来折腾博客了，从大学到现在折腾 hexo 了好多次了，但是每次做的都不尽如人意。昨晚上回到窝看邮箱发现去年在 namesilo 上买的域名（对，就现在这个）已经过期了，突然心血来潮，本来很困的我顿时来了精神，搞搞搞一直搞到两点，不知道是有了很多次失败的经历还是因为这次主题选择的好又或者是这次很明智地没有过分折腾，做出来的效果居然还不错，心满意足。但是还是得告诫自己，不要过分折腾这些东西，roi 实在很低。","link":"/2020/09/12/%E4%B8%83%E5%85%AB%E6%9C%88%E7%9A%84%E4%BA%8C%E4%B8%89%E4%BA%8B/"},{"title":"redis-基础数据结构-hyperloglog（二）源码与设计","text":"上一篇文章介绍了 HyperLogLog 的工作原理，这里介绍一下 redis 中的具体实现 从伯努利实验到UV计数从伯努利实验中我们可以通过连续反面的次数来估算抛掷次数，而 HyperLogLog 正是利用的这个原理来实现诸如UV计数等功能。那么如何将UV计数和伯努利实验联系起来呢？HLL 适用于字符串，redis 将其哈希，得到二进制哈希值的0、1就可以和硬币的正反面对应；通过统计其哈希值连续 0 的个数从而对应连续出现反面的次数 所以按照伯努利实验的思路，我们只需要一个计数器，记录下当前哈希值，每次计算添加元素的哈希值的最低位开始的0的个数，如果比当前的大，就更新这个计数器。但是，从伯努利实验中我们也看到只抛一轮实验计算得到的结果误差是比较大的，所以会抛多轮并计算其平均值（或者加权平均）进行优化。HLL 也是类似，它用了 16384 个计数器，哈希值的低14位用于确定计数器，高50位用于计算连续0的个数，从而达到平均的效果。 当使用PFADD命令添加一个元素时，首先将该元素哈希为一个 uint64，并且通过哈希值的低14bit定位到它所在的 register，然后计算该哈希值从15位开始连续为 0 的 bit 的个数，如果新元素的连续 0bit 个数大于该 register，那么就更新 register。 下面这个函数用于确定 register 的下标并计算连续为 0 的 bit 的个数： 1234567891011121314151617int hllPatLen(unsigned char *ele, size_t elesize, long *regp) { uint64_t hash, bit, index; int count; hash = MurmurHash64A(ele,elesize,0xadc83b19ULL); index = hash &amp; HLL_P_MASK; /* Register index. */ hash &gt;&gt;= HLL_P; /* Remove bits used to address the register. */ hash |= ((uint64_t)1&lt;&lt;HLL_Q); /* Make sure the loop terminates and count will be &lt;= Q+1. */ bit = 1; count = 1; /* Initialized to 1 since we count the &quot;00000...1&quot; pattern. */ while((hash &amp; bit) == 0) { count++; bit &lt;&lt;= 1; } *regp = (int) index; return count;} 这里有几点需要注意： 终结连续 0bit 串的 1 也需要被包含进来，比如 001，其计数值为 3； 数据结构hll 底层使用的是 sds 存储数据，并且通过一个 header 来管理数据： 1234567struct hllhdr { char magic[4]; /* &quot;HYLL&quot; */ uint8_t encoding; /* HLL_DENSE or HLL_SPARSE. */ uint8_t notused[3]; /* Reserved for future use, must be zero. */ uint8_t card[8]; /* Cached cardinality, little endian. */ uint8_t registers[]; /* Data bytes. */} magic：即 H、Y、L、L 四个字母的 ascii 值，用以和其他 sds 区别 encoding：针对不同的场景，redis 会采用不同的编码方式，目前一共有 3 种编码方式 card：即 cardinality，用以缓存数目，最高位为 1 表示缓存是有效的，此时pfcount命令直接拿这个数值，否则就需要重新计算 registers：存储着所有的计数器 hllhdr中的registers柔性数组一共有 16384 个 register，每个 register 占 6bit。为什么是 6bit 呢？因为一个int64最多只有 64 个 bit 为 0，用 6bit 就可以表示了。 三种编码方式按照hllhdr的布局，一个 HLL 初始条件下就得占用 4+1+3+8+(16384*6/8)= 12304byte，也就是差不多 12KB，在 redis 中这被称为 dense 编码；而很多时候我们计数可能没有那么多，其中很多 register 都是 0，这个时候也占用 12KB 有些浪费；所以对于大部分 register 为 0 的情况，redis 提出了 sparse 编码；此外，在PFMERGE命令的实现中，还使用到了另外一种编码方式。 sparse 编码既然大多数 register 的值都为 0，那么可以想象，我们不直接存储 0 值，而是存储为 0 的 register 的个数，就可以达到节省内存的目的。而事实上 redis 也的确是这么做的，并且实现了更加精细的粒度控制， 对于 sparse 编码，redis 存储的是三种操作码： ZERO: 用 00xxxxxx 来表示，其中 xxxxxx 表示连续为 0 的 register 的个数 XZERO: 用 01xxxxxx yyyyyyyy 双字节来表示连续为 0 的 register 的个数，XZERO 只能表示 register &lt;= 64 的情况，而 XZERO 则可以表示更多 VAL: 用 1vvvvvvxx 来表示连续多个 register 的值相等情况，其中 vvvvv 表示的是 register 的值，xx 表示的是 register 的个数 有几点需要注意： 其实 opcode 表示的 register 的真实数目要在其数值的基础上 +1，因为 0个 register 其实是没有意义的 XZERO 中的两个字节，xxxxxx 是高位，yyyyyyyy 是低位 123#define HLL_SPARSE_ZERO_LEN(p) (((*(p)) &amp; 0x3f)+1)#define HLL_SPARSE_XZERO_LEN(p) (((((*(p)) &amp; 0x3f) &lt;&lt; 8) | (*((p)+1)))+1)#define HLL_SPARSE_VAL_LEN(p) (((*(p)) &amp; 0x3)+1) 为什么这样设计呢？ 不同的 opcode，需要使用若干 bit 来进行区分定义 首先要考虑到创建 hll 时 16384 个 register 都为 0 的情况，这样就至少需要 14 个 bit，也就是说 2byte 用两个字节来表示 0 比较浪费，可能存在少量连续 register 为 0 的情况，这个可以用 1 byte 来表示 需要考虑到连续多个 register 为同一数值（不一定是 0）的情况 这样有哪些限制呢？ 可以看到 VAL 指令能表示的 register 的值最大为 32，所以 sparse 形态的 hyperloglog 也要求所有 register 值最大为 32，否则就需要转为 dense 形态 VAL 能表示的具有相同值的 register 的个数最多为 4，这我感觉也是经过考量的，因为用 2bit 表示 3 种类型，所以有一种类型可以用一个 bit 表示即可，多出来的 bit 可以作为计数使用（比如 1vvvvvxxx 这样可以最多以及最大表示连续 8 个值为 16 的 register sparse 升级到 dense在两种情况下，稀疏形态会被转换为稠密形态： 某个 register 的值大于 32 总的 hyperloglog 的大小大于server.hll_sparse_max_bytes配置项的值 123456789101112131415161718192021222324252627282930313233343536373839404142int hllSparseToDense(robj *o) { sds sparse = o-&gt;ptr, dense; struct hllhdr *hdr, *oldhdr = (struct hllhdr*) sparse; int idx = 0, runlen, regval; uint8_t *p = (uint8_t*)sparse, *end = p+sdslen(sparse); dense = sdsnewlen(NULL,HLL_DENSE_SIZE); hdr = (struct hllhdr *) dense; *hdr = *oldhdr; // 拷贝原来 header 中的 magic 和 card hdr-&gt;encoding = HLL_DENSE; p += HLL_HDR_SIZE; while (p &lt;= end) { if (HLL_SPARSE_IS_ZERO(p)) { runlen = HLL_SPARSE_ZERO_LEN(p) idx += runlen; p++; } else if (HLL_SPARSE_IS_XZERO) { runlen = HLL_SPARSE_XZERO_LEN(p); idx += runlen; p += 2; } else { runlen = HLL_SPARSE_VAL_LEN(p); regval = HLL_SPARSE_VAL_VALUE(p); if ((runlen + idx) &gt; HLL_REGISTERS) break; while (runlen--) { HLL_DENSE_SET_REGISTER(hdr-&gt;registers,idx,regval); idx++; } p++; } } if (idx != HLL_REGISTERS) { sdsfree(dense); return C_ERROR; } sdsfree(sparse); o-&gt;ptr = dense; return C_OK;} 代码比较简单，主要是注意错误处理，防止内存越界，其中类似的 for 循环在 sparse 编码相关的多个函数中都使用到了。 sparse 编码下如何存取数据和 dense 编码一样，sparse 编码也有存取数据的操作，其中 set 操作比较复杂，需要仔细理解： 首先是检查 set 的值是否超出了 32，这是VAL类型的 opcode 所能存储的最大数值，超出了就得升级为 dense 编码。没有超出的话，那么就得尝试着往 sparse 里面 set 数值，而在 sparse 中进行 set 操作，可能会造成 opcode 的分裂，所以需要为分裂预留空间，最大的分裂情况是XZERO类型的 opcode 分裂为 XZERO|VAL|XZERO，增加了 3byte，所以先预分配 3byte。此外分裂可能造成 sparse 的大小超出了阈值从而导致 promote，不过得先尝试着 set 才知道会不会 promote： 然后定位到第 index 个 register 所在的 opcode，以及前一个和后一个 opcode。这里和前面 for 循环逻辑类似， 1234567891011121314151617181920212223while (p &lt; end) { long oplen; oplen = 1; if (HLL_SPARSE_IS_ZERO(p)) { span = HLL_SPARSE_ZERO_LEN(p); } else if (HLL_SPARSE_IS_XZERO(p)) { span = HLL_SPARSE_XZERO_LEN(p) } else { span = HLL_SPARSE_VAL_LEN(p); oplen = 2; } if (index &lt; fist+span-1) break; prev = p; p += oplen; first += span;}if (span == 0 || p &gt;= end) return -1;next = HLL_SPARSE_IS_ZERO(p) ? p+2 : p+1;if (next &gt;= end) next = NULL; 我感觉这样的循环是最难控制的，以及如何确定循环结束时各个变量的状态，原来看《算法导论》的时候学到”循环不变式”方法用的也不是很顺手 当循环结束，p指向第 index 个 register 所在的 opcode，并且由is_zero、is_xzero和is_val指明该 opcode 的类型，first 指向的是该 opcode 包含的第一个 register 的下标，next 和 prev 分别表示前一个和后一个 opcode（当p是第一个或者最后一个 opcode 的话，对于的prev和next可能为NULL） 随后 redis 处理了几种比较特殊但是不需要分裂、容易处理的情况: p 是一个 VAL 类型的 opcode，而且其值 &gt;= count，此时无需更新 p 是一个 VAL 类型的 opcode，长度为 1， 且其值 &lt; count，此时更新其值即可 p 是一个长度为 1 的 ZERO 类型的 opcode，此时只需要将其类型更新为 VAL，并且设置其值为 count 即可 这里有一点需要注意，对于 case2 和 case3，更新 VAL 之后，p 和其左右的 opcode 可能是可以合并的，redis 会在 updated 中做这个优化。 如果以上的几种特殊情况都不满足，那么就必须分裂 opcode，而 opcode 被分裂后最长有 5byte，所以 redis 将分裂后的数据存储在一个长度为 5byte 的临时缓存区内，然后将原来的内存缓冲区腾出合适大小的空间，并把临时缓冲区中的数据拷贝进去；举一个 VAL 类型的 opcode 分裂的情况： 12345678910111213141516171819202122232425262728293031uint8_t seq[5]; *n = seq;int last = first+span-1;int len;if (is_zero || is_xzero) { ...} else { curval = HLL_SPARSE_VAL_VALUE(p); if (index != first) { len = index-first; HLL_SPARSE_VAL_SET(n,curval,len); n++ } HLL_SPARSE_VAL_SET(n,count,1); n++; if (index != last) { len = last-index; HLL_SPARSE_VAL_SET(n,curval,len); n++ }}int seqlen = n-seq;int oldlen = is_xzero ? 2 : 1;int deltalen = oldlen - len;if (deltalen &gt; 0 &amp;&amp; sdslen(o-&gt;ptr)+delta &gt; server.hll_sparse_max_bytes) goto promote;if (deltalen &amp;&amp; next) memmove(next+deltalen, next, end-next);sdsIncrLen(o-&gt;ptr, deltalen);memcpy(p,seq,seqlen);end += deltalen; 需要注意的是此时仍可以优化： VAL 类型的 opcode 分裂，导致分裂出去的左右两个 opcode 可以和其相邻的 opcode 合并 opcode 从长度为 1 的 ZERO 更新为长度为 1 的 VAL，从而可以和其相邻 opcode 合并 opcode 从长度为 1 的 VAL 更新为长度仍为 1，但是值更大的 VAL，从而可以与其相邻的 opcode 合并 1234567891011121314151617181920212223242526272829updated: p = prev ? prev : sparse; int scanlen = 5; while (p &lt; end &amp;&amp; scanlen--) { if (HLL_SPARSE_IS_XZERO(p)) { p += 2; continue } else if (HLL_SPARSE_IS_ZERO(p)) { p++; continue } if (p+1 &lt; end &amp;&amp;&amp; HLL_SPARSE_IS_VAL(p+1)) { int v1 = HLL_SPARSE_VAL_VALUE(p); int v2 = HLL_SPARSE_VAL_VALUE(p+1); if (v1 == v2) { int len = HLL_SPARSE_VAL_LEN(p)+HLL_SPARSE_VAL_LEN(p+1) if (len &lt;= HLL_SPARSE_VAL_MAX_LEN) { HLL_SPARSE_VAL_SET(p+1,v1,len); // QUESTION: 为什么不是 memmove(p,p+1,end-p-1) memmove(p,p+1,end-p) sdsIncrLen(o-&gt;ptr,-1); end--; continue; } } } p++; } 大致思路： 如果 p 和 p+1 可以合并，那么将 p+1 的 value 置为原来 p 和 p+1 的值的和，然后将 [p+1, end) 移动到 p 的位置；此时依据从 p 的位置开始看下一个是否可以合并（也就是连续合并的情况） 有几点需要注意： 这里将scanlen限制为5，也就是说最多合并5个opcode，这是针对一个 VAL opcode 分裂为 3 个 VAL opcode 的情况（即上一张图片中的 case1） 连续合并的情况，只在 VAL opcode 的数值更新的情况下发生（即上一张图片中的 case2 和 case3） dense 编码存储格式dense 编码即使用完整的 16384 个 register。 但是我们存取数据的最小单元是 byte，即 8bit，而每个 register 只有 6bit，那么这 6bit 在 byte 中是怎样的摆放方式呢？ 那怎么取出来呢： 123456789#define HLL_DENSE_GET_REGISTER(target,p,regnum) do { \\ uint8_t *_p = (uint8_t*) p; \\ unsigned long _byte = regnum*HLL_BITS/8; \\ unsigned long _fb = regnum*HLL_BITS&amp;7; \\ unsigned long _fb8 = 8 - _fb; \\ unsigned long b0 = _p[_byte]; \\ unsigned long b1 = _p[_byte+1]; \\ target = ((b0 &gt;&gt; _fb) | (b1 &lt;&lt; _fb8)) &amp; HLL_REGISTER_MAX; \\} while(0) 首先计算出该 register 所在的第一个字节_byte 然后计算出该 register 第一个 bit 在该字节中的位置 再计算出该 register 在第下一个字节所在的 用图总结大概就是这样： 写入的过程比读取更加麻烦一些： 1234567891011#define HLL_DENSE_SET_REGISTER(p,regnum,val) do { \\ uint8_t *_p = (uint8_t*) p; \\ unsigned long _byte = regnum*HLL_BITS/8; \\ unsigned long _fb = regnum*HLL_BITS&amp;7; \\ unsigned long _fb8 = 8 - _fb; \\ unsigned long _v = val; \\ _p[_byte] &amp;= ~(HLL_REGISTER_MAX &lt;&lt; _fb); \\ _p[_byte] |= _v &lt;&lt; _fb; \\ _p[_byte+1] &amp;= ~(HLL_REGISTER_MAX &gt;&gt; _fb8); \\ _p[_byte+1] |= _v &gt;&gt; _fb8; \\} while(0) 首先计算出 然后 最后 dense 编码下的数据结构各个部分都是确定了的，不存在 sparse 编码中的诸如 opcode 分裂的情况，所以其存取还是比较简单的（当然前提是理解了其存储格式），就不再赘述 如何估算前面提到，HyperLogLog 和 LogLog 的不同之处在于 HLL 使用的是调和平均数，而不是平均数：$$H_n = \\frac{n}{\\frac{1}{x_1} + \\frac{1}{x_2} + \\frac{1}{x_3} + \\dots + \\frac{1}{x_n}} = \\frac{n}{\\sum\\limits_{i=1}^{n}{\\frac{1}{x_i}}}$$HLL 结合了调和平均数的公式：$$H_{hll} = const * m * \\frac{m}{\\sum\\limits_{j=1}^{m}\\frac{1}{2^{R_j}}}$$其中： const：用于修正结果的一个常数 m 表示桶的个数，默认为 16384 $R_j$ 表示每个桶的估计值 12345678910111213141516171819202122232425262728uint64_t hllCount(struct hllhdr *hdr, int *invalid) { double m = HLL_REGISTERS; double E; int j; int reghisto[64] = {0}; if (hdr-&gt;encoding == HLL_DENSE) { hllDenseRegHisto(hdr-&gt;registers,reghisto); } else (hdr-&gt;encoding == HLL_SPARSE) { hllSparseRegHisto(hdr-&gt;registers, sdslen((sds)hdr)-HLL_HDR_SIZE,invalid,reghisto); } else if (hdr-&gt;encoding == HLL_RAW) { hllRawRegHisto(hdr-&gt;registers,reghisto); } else { serverPanic(&quot;Unknown HyperLogLog encoding in hllCount()&quot;); } double z = m * hllTau((m-registero[HLLL_Q+1])/(double)m) for (j = HLL_Q; j &gt;= 1; --j) { z += reghisto[j]; z *= 0.5; } z += m * hllSigma(reghisto[0]/(double)m) E = hllround(HLL_ALPHA_INF*m*m/z) return (uint64_t)E;} 首先是以直方图的形式统计值为1、2、3、…、64 的桶各有多少个： 然后是求 z，这个数字其实就是上面公式中的求和部分 最后求 E 的过程，其形式和上面的公式是完全相同的，公式中的 const，就是这里的HLL_ALPHA_INF，其值为$\\frac{0.5}{ln_2}$ 其估算方法来自这篇论文，由于篇幅太长我数学也太差，就暂时不仔细阅读了，有兴趣的同学可以看看。 命令的实现PFCOUNT命令前面提到 HLL 一共有三种编码方式，其中 Raw 编码并没有暴露出去，而是只在PFCOUNT命令实现函数中用了。所谓 raw 编码，顾名思义就是原始编码，也就是一个字节表示一个 register，当使用PFCOUNT命令统计多个 HLL 对象时，redis 会创建一个 raw 编码的临时 hll object，用于将所有需要统计的 hll object 的 register 都统计到这个临时变量中，而后再计算得到估计值。 12345678910111213141516171819202122232425262728293031323334353637383940void pfcountCommand(client *c) { robj *o; struct hllhdr *hdr; uint64_t card; if (c-&gt;argc &gt; 2) { uint8_t max[HLL_HDR_SIZE+HLL_REGISTERS], *registers; int j; memset(max,0,sizeof(max)); hdr = (struct hllhdr*) max; hdr-&gt;encoding = HLL_RAW; registers = max + HLL_HDR_SIZE; for (j = 1; j &lt; c-&gt;argc; j++) { robj *o = lookupKeyRead(c-&gt;db, c-&gt;argv[i]); // set max[i] = MAX(max[i],hll[i]) hllMerge(registers,o); } addReplyLongLong(c,hllCount(hdr,NULL)); return; } o = lookupKeyWrite(c-&gt;db, c-&gt;argv[1]); hdr = o-&gt;ptr; if (HLL_VALID_CACHE(hdr)) { card = (uint64_t)hdr-&gt;card[0]; card |= (uint64_t)hdr-&gt;card[1] &lt;&lt; 8; ... } else { int invalid = 0; card = hllCount(hdr,&amp;invalid); hdr-&gt;card[0] = card &amp; 0xff; hdr-&gt;card[0] = (card &gt;&gt; 16) &amp; 0xff ... signalModifiedKey(c,c-&gt;db,c-&gt;argv[1]); server.dirty++; } addReplayLongLong(c,card);} 首先是统计多个 hll object 的情况，这里并不是单个单个统计而后求和。而是将其转换为单个 hll object 再求和。具体来说，就是使用一个 raw 编码临时 hll object，和每个待统计的 hll object 进行 merge 操作，最终该临时 hll object 中的每个 register 都是所有 hll object 中最大的那个。 而对于统计单个 hll object 的情况，首先检查其 header 中的缓存是否有效，如果仍有效就直接使用，否则需要重新计算估算值并更新缓存（这也是为什么使用lookupKeyWrite而不是lookupKeyRead的原因）。 一些思考编码与数学优化参考Redis new data structure: the HyperLogLog HyperLogLog 算法的原理讲解以及 Redis 是如何应用它的 Reids(4)——神奇的HyperLoglog解决统计问题","link":"/2020/10/03/redis-%E5%9F%BA%E7%A1%80%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-hyperloglog/"}],"tags":[{"name":"git","slug":"git","link":"/tags/git/"},{"name":"golang","slug":"golang","link":"/tags/golang/"},{"name":"websocket","slug":"websocket","link":"/tags/websocket/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"读书笔记","slug":"读书笔记","link":"/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"bug","slug":"bug","link":"/tags/bug/"},{"name":"okr","slug":"okr","link":"/tags/okr/"},{"name":"redis","slug":"redis","link":"/tags/redis/"}],"categories":[]}